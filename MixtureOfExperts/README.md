# Mixture of Experts

Adapted from the [Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer](https://arxiv.org/abs/1701.06538) paper.

You can find the `.pdf` file of the paper from the repo
